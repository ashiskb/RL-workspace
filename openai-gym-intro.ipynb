{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to OpenAI Gym\n",
    "## About Gym\n",
    "`Gym` is an open source Python library for developing and comparing `reinforcement learning` algorithms by providing a standard API to communicate between learning algorithms and environments, as well as a standard set of environments compliant with that API. \n",
    "* `Gym` documentation website is located [here](https://www.gymlibrary.dev/). \n",
    "* `Gym` also has a discord server for development purposes that you can join [here](https://discord.gg/nHg2JRN489).\n",
    "* `Gym`'s official developer site is [here](https://github.com/openai/gym).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "* `pip install gym`\n",
    "\n",
    "This does not include dependencies for all families of environments (there's a massive number, and some can be problematic to install on certain systems). You can install these dependencies for one family like `pip install gym[atari]` or use the following to install all dependencies.: \n",
    "* `pip install gym[all]`\n",
    "\n",
    "If the above pip install throws a bash/zsh error, it might be the subscripts not allowed there. You need to set option for that.\n",
    "* `setopt no_nomatch`\n",
    "\n",
    "Then run again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: gym[pong]\n"
     ]
    }
   ],
   "source": [
    "#!setopt no_nomatch\n",
    "#!pip install gym[pong]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import imageio.v2 as imageio\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing available `gym` environments\n",
    "\n",
    "```python\n",
    "#!/Users/ashis/venv-directory/venv-ml-p3.10/bin/python3.10\n",
    "#Please make this python file executable and then run it without passing it to python interpreter\n",
    "#as the the interpreter listed on the first line will be invoked. Good luck!\n",
    "#$ chmod +x list_all_envs_registry.py\n",
    "#$ ./list_all_envs_registry.py\n",
    "\n",
    "from gym import envs\n",
    "#all_envs = envs.registry.all()\n",
    "#env_ids = [env_spec.id for env_spec in all_envs]\n",
    "#pprint(sorted(env_ids))\n",
    "for key in envs.registry.keys():\n",
    "    print(key)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the Environment\n",
    "Gym implements the classic “agent-environment loop”:\n",
    "\n",
    "<img src=\"https://www.gymlibrary.dev/_images/AE_loop_dark.png\" style=\"background-color:black;\" width=300>\n",
    "\n",
    "The agent performs some `actions` in the environment (usually by passing some control inputs to the environment, e.g. torque inputs of motors) and observes how the `environment’s state` changes. One such action-observation exchange is referred to as a `timestep`.\n",
    "\n",
    "The goal in Reinforcement Learning (RL) is to manipulate the `environment` in some specific way. \n",
    "\n",
    "For instance, we want the agent to navigate a robot to a specific point in space. \n",
    "* If it succeeds in doing this (or makes some progress towards that goal), it will receive a `positive reward` alongside the observation for this `timestep`. \n",
    "* The reward may also be negative or 0, if the agent did not yet succeed (or did not make any progress). \n",
    "* The agent will then be trained to maximize the reward it accumulates over many timesteps.\n",
    "* After some timesteps, the environment may enter a terminal state. \n",
    "    * For instance, the robot may have crashed! In that case, we want to `reset the environment` to a new initial state. The environment issues a done signal to the agent if it enters such a terminal state. \n",
    "    * Not all done signals must be triggered by a “catastrophic failure”: Sometimes we also want to issue a done signal after a fixed number of timesteps, or if the agent has succeeded in completing some task in the environment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent-Environment loop in `Gym`\n",
    "* Here below are few examples of agent-environment loop in `gym`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LunarLander-v2\n",
    "\n",
    "* This example will run an instance of `LunarLander-v2` environment for `n` timesteps. \n",
    "* Since we pass `render_mode=\"human\"`, you should see a window pop up rendering the environment.\n",
    "* Save the following in a file named `lunarlanderv2.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/Users/ashis/venv-directory/venv-ml-p3.10/bin/python3.10\n",
    "#Please make this python file executable and then run it without passing it to python interpreter\n",
    "#as the the interpreter listed on the first line will be invoked. Good luck!\n",
    "#$ chmod +x lunarlanderv2.py\n",
    "#$ ./lunralanderv2.py\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "\n",
    "#number of timestepts\n",
    "n = 500\n",
    "\n",
    "#Since we pass render_mode=\"human\", you should see a window pop up rendering the environment.\n",
    "env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "env.action_space.seed(42)\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in tqdm(range(n)):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        #break\n",
    "\n",
    "env.close()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Every environment specifies the format of valid actions by providing an `env.action_space` attribute. \n",
    "* Similarly, the format of valid observations is specified by `env.observation_space`. \n",
    "* In the example above we sampled random actions via `env.action_space.sample()`. \n",
    "* Note that we need to seed the action space separately from the environment to ensure reproducible samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALE/Breakout-v5\n",
    "\n",
    "* This example will run an instance of `ALE/Breakout-v5` environment for `n` timesteps. \n",
    "* Since we pass `render_mode=\"human\"`, you should see a window pop up rendering the environment.\n",
    "* Save the following in a file named `ALE-Breakout-v5_code1.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/Users/ashis/venv-directory/venv-ml-p3.10/bin/python3.10\n",
    "#Please make this python file executable and then run it without passing it to python interpreter\n",
    "#as the the interpreter listed on the first line will be invoked. Good luck!\n",
    "#$ chmod +x ALE-Breakout-v5_code1.py\n",
    "#$ ./ALE-Breakout-v5_code1.py\n",
    "\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "\n",
    "#number of timestepts\n",
    "n = 500\n",
    "\n",
    "#Since we pass render_mode=\"human\", you should see a window pop up rendering the environment.\n",
    "env = gym.make(\"ALE/Breakout-v5\", render_mode=\"human\")\n",
    "env.action_space.seed(42)\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in tqdm(range(n)):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        #break\n",
    "\n",
    "env.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackjack-v1\n",
    "\n",
    "* This example will run an instance of `Blackjack-v1` environment for `n` timesteps. \n",
    "* Since we pass `render_mode=\"human\"`, you should see a window pop up rendering the environment.\n",
    "* Save the following in a file named `Blackjack-v1_code1.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/Users/ashis/venv-directory/venv-ml-p3.10/bin/python3.10\n",
    "#Please make this python file executable and then run it without passing it to python interpreter\n",
    "#as the the interpreter listed on the first line will be invoked. Good luck!\n",
    "#$ chmod +x Blackjack-v1-code1.py\n",
    "#$ ./Blackjack-v1-code1.py\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "\n",
    "#number of timestepts\n",
    "n = 500\n",
    "\n",
    "#Since we pass render_mode=\"human\", you should see a window pop up rendering the environment.\n",
    "env = gym.make(\"Blackjack-v1\", render_mode=\"human\")\n",
    "env.action_space.seed(42)\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in tqdm(range(n)):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        #break\n",
    "\n",
    "env.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CarRacing-v2\n",
    "\n",
    "* This example will run an instance of `CarRacing-v2` environment for `n` timesteps. \n",
    "* Since we pass `render_mode=\"human\"`, you should see a window pop up rendering the environment.\n",
    "* Save the following in a file named `CarRacing-v2_code1.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/Users/ashis/venv-directory/venv-ml-p3.10/bin/python3.10\n",
    "#Please make this python file executable and then run it without passing it to python interpreter\n",
    "#as the the interpreter listed on the first line will be invoked. Good luck!\n",
    "#$ chmod +x CarRacing-v2-code1.py\n",
    "#$ ./CarRacing-v2-code1.py\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "\n",
    "#number of timestepts\n",
    "n = 500\n",
    "\n",
    "#Since we pass render_mode=\"human\", you should see a window pop up rendering the environment.\n",
    "env = gym.make(\"CarRacing-v2\", render_mode=\"human\")\n",
    "env.action_space.seed(42)\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in tqdm(range(n)):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        #break\n",
    "\n",
    "env.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pong-v0\n",
    "\n",
    "* This example will run an instance of `Pong-v0` environment for `n` timesteps. \n",
    "* Since we pass `render_mode=\"human\"`, you should see a window pop up rendering the environment.\n",
    "* Save the following in a file named `pongv0_code1.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/Users/ashis/venv-directory/venv-ml-p3.10/bin/python3.10\n",
    "#Please make this python file executable and then run it without passing it to python interpreter\n",
    "#as the the interpreter listed on the first line will be invoked. Good luck!\n",
    "#$ chmod +x pongv0_code1.py\n",
    "#$ ./pongv0_code1.py\n",
    "\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "\n",
    "#number of timestepts\n",
    "n = 500\n",
    "\n",
    "#Since we pass render_mode=\"human\", you should see a window pop up rendering the environment.\n",
    "env = gym.make(\"Pong-v0\", render_mode=\"human\")\n",
    "env.action_space.seed(42)\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in tqdm(range(n)):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        #break\n",
    "\n",
    "env.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Riverraid-v0\n",
    "\n",
    "* This example will run an instance of `Riverraid-v0` environment for `n` timesteps. \n",
    "* Since we pass `render_mode=\"human\"`, you should see a window pop up rendering the environment.\n",
    "* Save the following in a file named `Riverraid-v0_code1.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/Users/ashis/venv-directory/venv-ml-p3.10/bin/python3.10\n",
    "#Please make this python file executable and then run it without passing it to python interpreter\n",
    "#as the the interpreter listed on the first line will be invoked. Good luck!\n",
    "#$ chmod +x Riverraid-v0_code1.py\n",
    "#$ ./Riverraid-v0_code1.py\n",
    "\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "\n",
    "#number of timestepts\n",
    "n = 500\n",
    "\n",
    "#Since we pass render_mode=\"human\", you should see a window pop up rendering the environment.\n",
    "env = gym.make(\"Riverraid-v0\", render_mode=\"human\")\n",
    "env.action_space.seed(42)\n",
    "\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "for _ in tqdm(range(n)):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    \n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        #break\n",
    "\n",
    "env.close()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with `Cartpole-v0` environment\n",
    "* This environment is from the [classic control group](https://www.gymlibrary.dev/environments/classic_control/)\n",
    "* **Goal** is to control the cart (i.e., platform) with a pole attached by its bottom prt.\n",
    "* **Trick**: The pole tends to fall right or left and you would need to balance it by moving the cart to the right or left on every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashis/venv-directory/venv-ml-p3.10/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State space (observable)\n",
    "* The observation of the environment is 4 floating point numbers: [position of cart, velocity of cart, angle of pole, rotation rate of pole]\n",
    "    1. x-coordinate of the pole's center of mass\n",
    "    2. the pole's speed\n",
    "    3.  the pole's angle to the cart/platform. the pole angle in radians (1 radian = 57.295 degrees)\n",
    "    4. the pole's rotation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs = [ 0.04054569 -0.03567298  0.0173007   0.02051942]\n"
     ]
    }
   ],
   "source": [
    "obs,info = env.reset()\n",
    "print('obs = {}'.format(obs))\n",
    "#Example printout:\n",
    "# obs = [-0.02007766 -0.00363281 -0.0034504  -0.02222458]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem is to find the `best action` per step\n",
    "* We need to convert these 4 observations to into actions. \n",
    "* But, how do we learn to balance this system without knowing the exact meaning of the observed 4 numbers by getting the reward? \n",
    "* Here, the reward is 1; and it is given on every time step.\n",
    "* The episode continues until the pole falls.\n",
    "* To get a more accumulated reward, we need to balance the platform, as long as possible, in a way to avoid the pole falling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env.action_space = Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "print('env.action_space = {}'.format(env.action_space))\n",
    "#Example printout:\n",
    "# env.action_space = Discrete(2)\n",
    "#only 2 actions: 0 or 1, where 0 means pushing the platform to the left, 1 means to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env.observation_space = Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "env.observation_space.high = [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
      "env.observation_space.low = [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
     ]
    }
   ],
   "source": [
    "print('env.observation_space = {}'.format(env.observation_space))\n",
    "#Example printout:\n",
    "# env.observation_space = Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
    "#The observation space is a 4-D space, and each dimension is as follows:\n",
    "#Num Observation             Min         Max\n",
    "#0   Cart Position           -2.4        2.4\n",
    "#1   Cart Velocity           -Inf        Inf\n",
    "#2   Pole Angle              ~ -41.8°    ~ 41.8°\n",
    "#3   Pole Velocity At Tip    -Inf        Inf\n",
    "#env.observation_space.low and env.observation_space.high which will print the minimum and maximum values for each observation variable.\n",
    "print('env.observation_space.high = {}'.format(env.observation_space.high))\n",
    "print('env.observation_space.low = {}'.format(env.observation_space.low))\n",
    "#Example printout:\n",
    "#env.observation_space.high = [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
    "#env.observation_space.low = [-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply a specific action at a step\n",
    "* How about going left, i.e., action=0 from the action_space?\n",
    "    - result is a `new state`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation = [ 0.03983223 -0.23103872  0.01771109  0.3186103 ]\n",
      "reward = 1.0\n",
      "terminated = False\n",
      "truncated = False\n",
      "info = {}\n"
     ]
    }
   ],
   "source": [
    "observation, reward, terminated, truncated, info = env.step(0)\n",
    "print('observation = {}'.format(observation))\n",
    "print('reward = {}'.format(reward))\n",
    "print('terminated = {}'.format(terminated))\n",
    "print('truncated = {}'.format(truncated))\n",
    "print('info = {}'.format(info))\n",
    "#Example printout:\n",
    "#observation = [-0.02728556 -0.22667485 -0.01062018  0.3176722 ]\n",
    "#reward = 1.0\n",
    "#terminated = False\n",
    "#truncated = False\n",
    "#info = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply an random action at a step\n",
    "* The `sample()` returns a random sample from the given/supplied space.\n",
    "* Here below, you can see that we sample from the `action_space`.\n",
    "* The `sample()` can also be used to sample from the `observation_space` as well -- although why would we want to use that here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = 1\n"
     ]
    }
   ],
   "source": [
    "action = env.action_space.sample()\n",
    "print('action = {}'.format(action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = 0\n"
     ]
    }
   ],
   "source": [
    "#Let's apply another random action with sampling\n",
    "action = env.action_space.sample()\n",
    "print('action = {}'.format(action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action = 1\n"
     ]
    }
   ],
   "source": [
    "#Let's apply another random action with sampling\n",
    "action = env.action_space.sample()\n",
    "print('action = {}'.format(action))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random CartPole-v0 agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/Users/ashis/venv-directory/venv-ml-p3.10/bin/python3.10\n",
    "#Please make this python file executable and then run it without passing it to python interpreter\n",
    "#as the the interpreter listed on the first line will be invoked. Good luck!\n",
    "#$ chmod +x CartPole-v0-code3.py\n",
    "#$ ./CartPole-v0-code3.py\n",
    "import gym\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#The CartPole-v0 environment with a random agent\n",
    "# Goal is to control the cart (i.e., platform) with a pole attached by its bottom prt.\n",
    "# Trick: The pole tends to fall right or left and you would need to balance it by moving the cart to the right or left on every step.\n",
    "\n",
    "env = gym.make(\"CartPole-v0\",render_mode='human')\n",
    "\n",
    "#Here below, we created the environment and initialized few variables.\n",
    "total_reward = 0.0\n",
    "total_steps = 0\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    total_steps += 1\n",
    "\n",
    "    if terminated:\n",
    "        break\n",
    "\n",
    "print('Episode terminated in {} steps\\nTotal rewards accumulated = {}'.format(total_steps,total_reward))\n",
    "\n",
    "#On average, this random agent takes 12 to 15 steps before the pole falls and the episode ends\n",
    "#Most of the environments in Gym have a `reward boundary`, which is the average reward that the agent should gain during 100 consecutive eposides to solve the environment.\n",
    "#For cartpole, the boundary is 195. That means, on average, the agent must hold the stick for 195 time steps or longer.\n",
    "#So, our random agent's performance is extremely poor.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intelligent CartPole-v0 agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretizing continuous state space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_state(state, env, buckets=(1,1,6,12)):\n",
    "    \"\"\"    \n",
    "    The problem: The original states in this game are continuous, which does not work with the basic Q-learning algorithm as it expects discrete states. By the way, a slightly advanced Q-learning strategy can work with continuous state space with the help of approximation. Let's leave that strategy out of the scope of this course! Sorry. please enroll the \"AI with Reinforcement Learning\" course in Spring'23 with Dr. B. Purpose of this function is to discretize the continuous state space into buckets. \n",
    "\n",
    "    :param state: current state's observation which needs discretizing\n",
    "    :type state: 4-D float array\n",
    "    :param env: the cartpole environment\n",
    "    :type env: environment object returned most likely from a gym.make() call.\n",
    "    :param buckets: this will be used to discretize the original continuous states in this Cartpole example, defaults to (1,1,6,12)\n",
    "    :type buckets: tuple, optional\n",
    "    :return: The discretized state space in the given buckets\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    ## [position of cart, velocity of cart, angle of pole, rotation rate of pole]\n",
    "    ## i) x-coordinate of the pole's center of mass (i.e., cart position), unit: m\n",
    "    ## ii) Cart velocity [-inf, inf], unit: m/s\n",
    "    ## iii) the pole's angle to the cart/platform. the pole angle in radians (1 radian = 57.295 degrees); \n",
    "    ## iv) the pole's angular velocity [-inf, inf], unit: radian/s\n",
    "    \n",
    "\n",
    "    # Revising the upper and the lower bounds for the discretization\n",
    "    # Please note: cart velocity upper and lower bounds are 3.4e38 (inf), -3.4e38 (-inf). That's a huge space!\n",
    "    # Let's shrink it down to [0.5, -0.5]\n",
    "\n",
    "    # Also note: pole's angular velocity upper and lower bounds are 3.4e38 (inf), -3.4e38 (-inf). That's also a huge space!\n",
    "    # Let's shrink it down to [50 degrees/1 sec, -50 degrees/1 sec]\n",
    "    \n",
    "    upper_bounds = [env.observation_space.high[0], 0.5, env.observation_space.high[2], math.radians(50) / 1.]\n",
    "    lower_bounds = [env.observation_space.low[0], -0.5, env.observation_space.low[2], -math.radians(50) / 1.]\n",
    "\n",
    "    # state is the native state representations produced by env\n",
    "    ratios = [(state[i] + abs(lower_bounds[i])) / (upper_bounds[i] - lower_bounds[i]) for i in range(len(state))]\n",
    "    \n",
    "    # state_ is discretized state representation used for Q-table later\n",
    "    state_ = [int(round((buckets[i] - 1) * ratios[i])) for i in range(len(state))]\n",
    "    state_ = [min(buckets[i] - 1, max(0, state_[i])) for i in range(len(state))]\n",
    "\n",
    "    return tuple(state_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon-greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, env, Q_table, exploration_rate):\n",
    "    \"\"\"This is an epsilon greedy policy. In other words, most of the times the agent chooses the action that maximizes the reward given state (greedily). But occassionally (controlled by the exploration_rate), the agent chooses a random action which makes sure the agent balances between exploitation and exploration\n",
    "\n",
    "    :param state: the current state the agent is at.\n",
    "    :type state: same as state\n",
    "    :param env: the CartPole environment\n",
    "    :type env: environment type returned perhaps from gym.make() call.\n",
    "    :param Q_table: a table-like structure\n",
    "    :type Q_table: same as Q_table\n",
    "    :param exploration_rate: exploration rate\n",
    "    :type exploration_rate: a small number close to 0.\n",
    "    :return: action to be taken in the next step\n",
    "    :rtype: between any value in the action_space. E.g., {0 (left), 1 (right)}\n",
    "    \"\"\"\n",
    "    if (np.random.random() < exploration_rate):\n",
    "        # Generates numbers np.random.random() uniformly between 0-1\n",
    "        # This samples a random action given the environment\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        # Choose greedily the action which gives the highest expected reward\n",
    "        # given the current state\n",
    "        return np.argmax(Q_table[state])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate decay strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate_with_decay(t, decay_rate=25.0):\n",
    "    \"\"\"Get the learning rate or exploration_rate given an episode subject to decay. \n",
    "    Given the current episode number and the rate has a tendency to decrease with increasing number of episodes.\n",
    "\n",
    "    :param t: episode number\n",
    "    :type t: int\n",
    "    :param decay_rate: decay rate, defaults to 25%\n",
    "    :type decay_rate: float\n",
    "    :return: decayed alpha value\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    decayed_alpha = max(0.1, min(1., 1. - np.log10((t + 1) / decay_rate)))\n",
    "    return decayed_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Q-table (for one step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q(Q_table, state, action, reward, new_state, alpha, gamma):\n",
    "    \"\"\"Q-learning update step.\n",
    "\n",
    "    :param Q_table: a table-like structure with N rows for states and M columns for actions\n",
    "    :type Q_table: numpy array of shape (shape(discretized_state_space),shape(action_space)). Example: (1,1,6,12,2), where (1,1,6,12) is the shape of discretized state space, and (2,) is the shape of action space.\n",
    "    :param state: the current state the agent is at time step t.\n",
    "    :type state: numpy array of shape(discretized_state_space)\n",
    "    :param action: the action taken given the previous state at time step t\n",
    "    :type action: int\n",
    "    :param reward: reward collected as a result of that action at time step t\n",
    "    :type reward: int\n",
    "    :param new_state: the new state at time-step t+1\n",
    "    :type new_state: same as state\n",
    "    :param alpha: learning rate\n",
    "    :type alpha: float\n",
    "    :param gamma: discount factor\n",
    "    :type gamma: float\n",
    "    :return: updated Q_table\n",
    "    :rtype: same shape of the given Q_table\n",
    "    \"\"\"\n",
    "    Q_table[state][action] = Q_table[state][action] + alpha * (reward + gamma * np.max(Q_table[new_state]) - Q_table[state][action])\n",
    "    return Q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_learning(env, num_episodes, gamma=0.98):\n",
    "    \"\"\"Training the agent with Q-learning with respect to pseudocode in Algorithm 1\n",
    "\n",
    "    :param env: the cartpole environment\n",
    "    :type env: environment object likely returned from a gym.make() call.\n",
    "    :param num_episodes: the number of episodes for which to train\n",
    "    :type num_episodes: int\n",
    "    :param gamma: Discount factor gamma represents how much does the agent value future rewards as opposed to immediate rewards.\n",
    "    :type gamma: float\n",
    "    :return: The optimized Q-table\n",
    "    :rtype: (dim(discretized_state_space)+dim(action_space)), e.g., (1,1,6,12,2) in CartPole-v0\n",
    "    :return: A list containing the total cummulative reward for each episode of training.\n",
    "    :rtype: list of length==num_episodes\n",
    "    \"\"\"\n",
    "\n",
    "    # (1, 1, 6, 12) represents the discretization buckets.\n",
    "    # Initialize the Q-table as full of zeros at the start.\n",
    "    # Shape of Q_table would be = (1,1,6,12,  2), as there are 2 actions.\n",
    "    Q_table = np.zeros((1, 1, 6, 12) + (env.action_space.n,))\n",
    "\n",
    "    # Create a list to store the accumulated reward per each episode\n",
    "    total_reward = []\n",
    "    for e in tqdm(range(num_episodes)):\n",
    "\n",
    "        # Reset the environment for a new episode, get the default state S_0\n",
    "        state,info = env.reset()\n",
    "        #convert the continuous state to discrete state\n",
    "        state = discretize_state(state, env)\n",
    "\n",
    "        # Adjust the alpha and the exploration rate, it is a coincidence they are the same.\n",
    "        alpha = exploration_rate = get_rate_with_decay(e)\n",
    "        \n",
    "        # Initialize the current episode reward to 0 \n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        while done is False:\n",
    "            # Choose the action A_{t} based on the policy\n",
    "            action = epsilon_greedy_policy(state, env, Q_table, exploration_rate)\n",
    "\n",
    "            # Get the new state (S_{t+1}), reward (R_{t+1}), end signal\n",
    "            new_state, reward, done, _, _ = env.step(action)\n",
    "            #convert the continuous state to discrete state\n",
    "            new_state = discretize_state(new_state, env)\n",
    "\n",
    "            # Update Q-table via update_q(Q_table, S_{t}, A_{t}, R_{t+1}, S_{t+1}, alpha, gamma) \n",
    "            Q_table = update_Q(Q_table, state, action, reward, new_state, alpha, gamma)\n",
    "\n",
    "            # Update the state S_{t} = S_{t+1}\n",
    "            state = new_state\n",
    "            \n",
    "            # Accumulate the reward\n",
    "            episode_reward += reward\n",
    "        \n",
    "        total_reward.append(episode_reward)\n",
    "    print('Finished training!')\n",
    "    return Q_table, total_reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Q-learning agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashis/venv-directory/venv-ml-p3.10/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "#Now, let's begin train\n",
    "# OpenAI Gym builds the environment for us including all the rules, dynamics etc.\n",
    "env = gym.make('CartPole-v0',render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can tune verbosity of cell executions\n",
    "verbose = True\n",
    "\n",
    "# How long do we want the agent to explore and learn?\n",
    "num_episodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 281.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let us use Q-learning to learn best policy\n",
    "Q_table, total_reward = Q_learning(env, num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[[ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]]\n",
      "\n",
      "   [[24.71210507 26.97967061]\n",
      "    [19.36552249 24.78297896]\n",
      "    [16.2735539  26.49553617]\n",
      "    [17.57212113 17.61406818]\n",
      "    [ 8.21063206 24.59917008]\n",
      "    [ 7.35797894 18.82634129]\n",
      "    [ 1.39883516 16.38212077]\n",
      "    [ 0.          5.3843517 ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]]\n",
      "\n",
      "   [[39.464254   33.35214412]\n",
      "    [42.45996193 41.37632691]\n",
      "    [43.30377763 39.09147226]\n",
      "    [46.04908574 45.10822863]\n",
      "    [46.4304456  41.16349714]\n",
      "    [47.38819135 45.72096166]\n",
      "    [47.45463817 44.80132441]\n",
      "    [46.73390266 47.3744664 ]\n",
      "    [41.03495981 47.51337862]\n",
      "    [43.47194675 46.73617476]\n",
      "    [36.21946821 45.77860093]\n",
      "    [35.16151901 43.52222254]]\n",
      "\n",
      "   [[42.76218447 21.27813694]\n",
      "    [39.40187018 37.72833322]\n",
      "    [46.15285626 38.32446967]\n",
      "    [47.50954781 35.32473746]\n",
      "    [47.5401802  46.60351476]\n",
      "    [47.66038873 47.11804004]\n",
      "    [47.60103365 47.55516929]\n",
      "    [47.58285643 47.63965583]\n",
      "    [36.47059067 47.61806109]\n",
      "    [31.1948667  47.57709795]\n",
      "    [38.08439207 32.69275593]\n",
      "    [30.00990578 38.10094023]]\n",
      "\n",
      "   [[ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 4.81579124  0.        ]\n",
      "    [10.4329096   0.        ]\n",
      "    [13.40464354  1.64992239]\n",
      "    [18.87170249  5.14890821]\n",
      "    [19.40564766 11.01558211]\n",
      "    [19.89778969 16.92839818]\n",
      "    [21.35209434 13.92085244]\n",
      "    [21.44964463 22.25739279]]\n",
      "\n",
      "   [[ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]\n",
      "    [ 0.          0.        ]]]]] (1, 1, 6, 12, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['joblibs/Q_table.joblib']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if verbose:\n",
    "    #Plot\n",
    "    plt.plot(range(num_episodes), total_reward)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Training cumulative reward')\n",
    "    plt.show()\n",
    "\n",
    "    print(Q_table, Q_table.shape)\n",
    "\n",
    "#Saving the Q table for later use.\n",
    "dump(Q_table,'joblibs/Q_table.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Don't forget to closing the gym environment\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Q-learning agent after training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import imageio.v2 as imageio\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's run one episode\n",
    "\n",
    "max_episode_length = 400 #Duh! You wish!! It depends on how good your agent learned during training. \n",
    "\n",
    "# This way we can test the agent's recently learned policy with the saved Q_table\n",
    "Q_table = load('joblibs/Q_table.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Final test and viz. \n",
    "# Don't forget to switch to render_mode='rgb_array', otherwise env.render() will return None.\n",
    "env = gym.make('CartPole-v0',render_mode='rgb_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the reward\n",
    "episode_reward = 0\n",
    "\n",
    "# Count how many times the agent went right and how many times it went left\n",
    "right = 0\n",
    "left = 0\n",
    "\n",
    "# Initialize empty buffer for the images that will be stiched to a gif\n",
    "# Create a temp directory\n",
    "filenames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a temp directory\n",
    "try:\n",
    "    os.mkdir(\"./temp\")\n",
    "except:\n",
    "    #print('Error: file system readonly?')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained agent in a completely fresh start environment\n",
    "state,info = env.reset()\n",
    "# Don't forget to discretize the state_space the same way you did to train the agent\n",
    "state = discretize_state(state, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 42/400 [00:07<01:05,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test episode finished at step 43 with a total reward of: 43.0\n",
      "We moved 22 times right and 21 times left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run for maximum of max_episode_length steps which is the limit of the game\n",
    "for step in tqdm(range(max_episode_length)):\n",
    "\n",
    "    # Plot the previous state and save it as an image that \n",
    "    # will be later patched together sa a .gif\n",
    "    img = plt.imshow(env.render())\n",
    "\n",
    "    plt.title(\"Step: {}\".format(step))\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"./temp/{}.png\".format(step))\n",
    "    plt.close()\n",
    "    filenames.append(\"./temp/{}.png\".format(step))\n",
    "            \n",
    "    # Here we set the exploration rate to 0.0 as we want to avoid any random exploration.\n",
    "    # That is, we want the agent fully depends on its learned policy (+Q_table)\n",
    "    action = epsilon_greedy_policy(state, env, Q_table, exploration_rate=0.0)\n",
    "\n",
    "    #Just for statistics purpose\n",
    "    right+=1 if action == 1 else 0\n",
    "    left+=1 if action == 0 else 0\n",
    "\n",
    "    #Apply the next step\n",
    "    new_state, reward, done, _ , _ = env.step(action)\n",
    "    #Don't forget to discretize new_state\n",
    "    new_state = discretize_state(new_state, env)\n",
    "    state = new_state\n",
    "\n",
    "    #Collect/accumulate reward\n",
    "    episode_reward += reward\n",
    "\n",
    "    # At the end of the episode print the total reward, \n",
    "    # only the agent is done before the set max_episode_length steps.\n",
    "    # If your agent was trained well, who knows, the following would never happen! Haha\n",
    "    if done:\n",
    "        print(f'Test episode finished at step {step+1} with a total reward of: {episode_reward}')\n",
    "        print(f'We moved {right} times right and {left} times left')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitch the images together to produce a .gif\n",
    "with imageio.get_writer('./video/test.gif', mode='I') as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup the images for the next run\n",
    "for f in filenames:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Close the environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv-ml-p3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02e21343f826c236a58b28b5c79787633fe2e2a6d9ea6119a3d1b0f9c0c8d4d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
